{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<div class=\"row\">\n",
    "    <div class=\"column\">\n",
    "        <img src=\"https://datasciencecampus.ons.gov.uk/wp-content/uploads/sites/10/2017/03/data-science-campus-logo-new.svg\"\n",
    "             alt=\"Data Science Campus Logo\"\n",
    "             align=\"right\" \n",
    "             width = \"340\"\n",
    "             style=\"margin: 0px 60px\"\n",
    "             />\n",
    "    </div>\n",
    "    <div class=\"column\">\n",
    "        <img src=\"https://cdn.ons.gov.uk/assets/images/ons-logo/v2/ons-logo.svg\"\n",
    "             alt=\"ONS Logo\"\n",
    "             align=\"left\" \n",
    "             width = \"420\"\n",
    "             style=\"margin: 0px 30px\"/>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><font size=6>Chapter 2</font></h1></center>\n",
    "<center><h1><font size=7>Model Basics</h1></center>\n",
    "*By Dr. Laurie Baker and Dr. Daniel J. Lewis*\n",
    "\n",
    "## Introduction\n",
    "\n",
    " * Ideally your model will capture `signals` (i.e. patterns) generated by the phenomenom of interest and ignore `noise` (i.e. random variation) you're not interested in. \n",
    " \n",
    " * In model basics you will learn how models work mechanistically, focussing on the important family of linear models. \n",
    " \n",
    "**Hypothesis generation vs. hypothesis confirmation**\n",
    "\n",
    "  * Traditionally, one of the focuses of modelling is on **inference**, or confirming that a hypothesis is true. To do it correctly you need to know two things:\n",
    "  \n",
    "    1. Each observation can either be used for exploration or confirmation, not both. \n",
    "    2. You can use an observation as many times as you like for exploration, but you can only use it once for confirmation. As soon as you use an observation twice, you've switched from confirmation to exploration. \n",
    "    \n",
    "* Note, that in order to confirm a hypothesis, you must use data independent of the data used to generate the hypothesis.\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of Chapter 2, learners should know:\n",
    "\n",
    "*   Model Basics\n",
    "    *\t What is a model family and fitted model?\n",
    "    *\t What is the difference between a response and an explanatory variable?\n",
    "    \n",
    "*   Model Construction\n",
    "    *  How to construct a linear model in python?\n",
    "    *  What are the slope and intercept in a linear model?\n",
    "    *  Picking out key information from the model table\n",
    "    *  How to extract specific parameters from the model object.\n",
    "\n",
    "*  Assessing Model Fit\n",
    "    *\t How to inspect model residuals to assess model fit?\n",
    "    *\t How to pick out key information from the table from a fitted model. \n",
    "    *  How to use Adjusted R-squared and AIC to compare models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import matplotlib.pyplot as plt # data plotting\n",
    "import seaborn as sns # data visualisation and plotting\n",
    "import statsmodels.api as sm # statistical modelling package\n",
    "import statsmodels.formula.api as smf # statistical modelling package with R-like formulas\n",
    "import scipy.stats as stats # statistical modelling package\n",
    "import math # mathematical expressions\n",
    "\n",
    "from sklearn import datasets, linear_model # fetching iris dataset and linear model functions\n",
    "from sklearn.metrics import mean_squared_error, r2_score # packages to inspect residuals and Adjusted R^2\n",
    "\n",
    "# Seaborn plot default configurations\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# set the custom size for my graphs\n",
    "sns.set(rc={'figure.figsize':(8.7,6.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Model Basics\n",
    "\n",
    "## Introduction\n",
    "\n",
    " * Ideally your model will capture `signals` (i.e. patterns) generated by the phenomenom of interest and ignore `noise` (i.e. random variation) you're not interested in. \n",
    " \n",
    " * In model basics you will learn how models work mechanistically, focussing on the important family of linear models. \n",
    "\n",
    "\n",
    "## Model basics\n",
    "\n",
    "One of the goals of models is to partition data into patterns and residuals. Strong patterns will hide subtler trends. We can use models to peel back layers of structure as we explore a dataset. \n",
    "\n",
    "There are 2 key parts to a model, the family of models and the fitted model.\n",
    " \n",
    "\n",
    " 1. **Family of models**\n",
    "    * define a family of models that express precise, but generic pattern you wish to capture. For example, a straight line $y = ax + b$ or quadratic curve $y = ax^2 + bx + c$. Where $x$ and $y$ are known variables from your data, and $a$, $b$, and $c$ are parameters that can vary to capture different patterns. These formulas are simple to capture in python \n",
    "    \n",
    "    <br>\n",
    "\n",
    "<img src=\"../../images/clothesline.jpg\"  width=\"800\" height=\"800\" alt=\"A model family is like a piece of clothing you have different types and shapes depending on what the data is like.\">\n",
    "\n",
    "Image Credit: [Clothesline](https://www.flickr.com/photos/34379543@N06/3468402366) by [Frau Heimlich](https://www.flickr.com/photos/34379543@N06) is licensed under [CC BY-NC-SA 2.0](https://creativecommons.org/licenses/by-nc-sa/2.0/?ref=ccsearch&atype=rich)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    " 2. **Fitted model**\n",
    "    * After you've chosen your model family, the next step is to generate a fitted model from that family that is closest to your data. \n",
    "    * the **model family** is expressed as an equation, where the different parameters are able to take on different values to adjust the shape of the fitted line to the data.\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "<img src=\"../../images/tailor_fit.jpg\"  width=\"800\" height=\"800\" alt=\"If the model is the garment you can think of model like tailoring a garment to fit our data.\">\n",
    "\n",
    "Image Credit: [John Boyer Bespoke Suit Tailors](https://www.behance.net/gallery/30289889/John-Boyer-Bespoke-Suit-Tailors) by Shayna Grosh is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/?ref=ccsearch&atype=rich)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Note, it is important to understand that a fitted model is just the closest model from a family of models. What is \"best\" is determined according to some criteria, which we will discuss later.  \n",
    "\n",
    "**Clothes as an analogy**\n",
    "\n",
    "If we use clothes as an analogy, the **family of models** is like an assortment of garments you could choose to 'clothe' the data in. Just as some clothes will be more suitable than others depending on what you wish to do (e.g. nice dress to a wedding), the same is true for models. The type of model will depend on the type of data you have and what you wish to do with your analysis. \n",
    "\n",
    "**Model fitting** is similar to getting a garment tailored. Just as you might make alterations to improve the fit of a garment, you will adapt the chosen model to get a better fit to the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><font size=\"4\"> Terminology</font> </b> \n",
    "<p> \n",
    "\n",
    "In the field of data science you will see a number of terms used to refer to the same things. Here, we will use `response variable` to refer to the measured variable you are trying to explain. \n",
    "\n",
    "We will use `explanatory variables` to refer to the measured variables that we use to try to explain the response variable. Other terms that you may come across for these concepts include:\n",
    "\n",
    "* **response variable**: `dependent`, `target` (machine learning) \n",
    "\n",
    "* **explanatory variables**: `independent`, `features` (machine learning)\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "\n",
    "Linear regression is one of the most important and widely used regression techniques. Its main advantage is its simple structure and ease of interpreting results.\n",
    "\n",
    "Linear models take the mathematical form:\n",
    "\n",
    "$y = ax + b$\n",
    "\n",
    "where $y$ is the response variable, $a$ is the slope that quantifies the change in $y$ with increases in the dependent variable $x$, and $b$ is the intercept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Selling irises to nostalgic students**\n",
    "\n",
    "<img src=\"../../images/iris_classification.png\"  width=\"800\" height=\"800\" alt=\"Iris Varieties setosa, virginica, and versicolor vary in their sepal and petal lengths and widths.\">\n",
    "Image Credit:  Suruchi Fialoke, October 13, 2016, Classification of Iris Varieties.\n",
    "\n",
    "A data scientist is setting up a side business of breeding irises to sell to ex-statistics undergraduates who have rosy nostalgic memories of studying the iris dataset when they were budding statisticians. They are interested in the relationship between petal width and other metrics, like petal length, as they find that the irises with the widest petals sell better. \n",
    "\n",
    "Let's take a closer look at the iris data to explore the relationship between petal length and petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading and renaming the iris dataset\n",
    "\n",
    "# Define sklearn_to_df function to convert from sklearn to a pandas dataframes\n",
    "\n",
    "def sklearn_to_df(sklearn_dataset):\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Categorical.from_codes(sklearn_dataset.target, sklearn_dataset.target_names)\n",
    "    return df\n",
    "\n",
    "# import and convert format of iris data from sklearn to a pandas dataframe\n",
    "df_iris = sklearn_to_df(datasets.load_iris())\n",
    "\n",
    "\n",
    "df_iris = df_iris.rename(columns = {'sepal length (cm)': 'sepal_length', 'sepal width (cm)': 'sepal_width', 'petal length (cm)': 'petal_length', 'petal width (cm)': 'petal_width','target': 'species'})\n",
    "df_iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatterplot of petal length and petal widdth\n",
    "\n",
    "iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "iris_scatter_petal_length_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><font size=\"4\">Exercise:</font></b> \n",
    "\n",
    "<p> \n",
    "\n",
    "1. What kind of relationship do you see between petal width and petal length? How does petal width cahnge with petal length?\n",
    "\n",
    "</p> </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot it looks like there is a positive relationship between petal length and petal width. Let's use a model to capture the pattern and make it more explicit. In this case, the relationship looks linear so we can use the form: $y = ax + b$. We are interested in how petal width changes with petal length. We can make a guess at what the parameters for a and b might be. It looks like petal width increases more slowly than petal length, maybe at 0.3 cm for every 1 cm in petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(7)\n",
    "a = 0.3\n",
    "b = 0.1\n",
    "y = a*x + b\n",
    "\n",
    "\n",
    "iris_scatter_petal_length_width = sns.regplot(x=x, y=y, marker=\"+\")\n",
    "iris_scatter_petal_length_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, but maybe we could do a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(7)\n",
    "a = 0.37\n",
    "a1 = 0.35\n",
    "b = -0.2\n",
    "b1 = -0.3\n",
    "y = a*x + b\n",
    "y1 = a1*x + b1\n",
    "\n",
    "iris_scatter_petal_length_width = sns.regplot(x=x, y=y, marker=\"+\")\n",
    "iris_scatter_petal_length_width = sns.regplot(x=x, y=y1, marker=\"+\", line_kws={\"color\": \"red\"})\n",
    "iris_scatter_petal_length_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><font size=\"4\">Exercise:</font></b> \n",
    "\n",
    "<p> \n",
    "\n",
    "1. Your turn, what values would you put for the slope (a2) and the intercept (b2)? Fill in the blanks below to create your own line.\n",
    "\n",
    "</p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scatter_petal_length_width = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(7)\n",
    "a = 0.37\n",
    "a1 = 0.35\n",
    "a2 = \n",
    "b = -0.2\n",
    "b1 = -0.3\n",
    "b2 = \n",
    "y = a*x + b\n",
    "y1 = a1*x + b1\n",
    "y2 = \n",
    "\n",
    "iris_scatter_petal_length_width = sns.regplot(x=x, y=y, marker=\"+\")\n",
    "iris_scatter_petal_length_width = sns.regplot(x=x, y=y1, marker=\"+\", line_kws={\"color\": \"red\"})\n",
    "iris_scatter_petal_length_width = sns.regplot(x=x, y=y2, marker=\"+\", line_kws={\"color\": \"orange\"})\n",
    "\n",
    "iris_scatter_petal_length_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by now, all three lines have slightly different parameters. It is difficult to tell by eye which line fits the data better. We could do this ourselves, by measuring the `residuals`, the distance from the data (actual response) to the line (predicted response), for each model, and comparing them. But this can be time-consuming, especially if our goal is to find the best model which could involve looking at more than just two models! \n",
    "\n",
    "\n",
    "Luckily python has built-in functions that will explore all the possibilities to find the 'best' line. In linear regression, one of the ways to define the 'best' line is by finding the line that minimizes the sum of squared residuals (aka sum of squares). \n",
    "\n",
    "Calculating the sum of squared residuals involves taking the residual distances, squaring them, and summing them. This approach is also called Ordinary Least Squares (OLS), after which the OLS function in python takes its name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "Here we use the `statsmodels function api` to construct our models. This allows us to specify an intuitive model formula for our analyses where `formula = y ~ x`. \n",
    "\n",
    "In this case `y` is our response variable, the tilde \\tilde means \"depends on\" `x`, which represents an explanatory variable (i.e. the variable we are using to try to explain the variation in y). \n",
    "\n",
    "#### Model 1: Continuous Variable\n",
    "\n",
    "Let's take a look at what this looks like in practice. In this case we're interested in explaining the variation in `petal_width` using the explantory variable, `petal_length`.\n",
    "\n",
    "Note that the smf.ols function automatically includes the intercept in the model, so we don't have to specify one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = smf.ols(formula = 'petal_width ~ petal_length', data = df_iris)\n",
    "\n",
    "results_mod1 = model1.fit()\n",
    "\n",
    "print(results_mod1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary gives us a range of diagnostic information about the model we've fitted, split into three tables. Here's a quick guide on what is included:\n",
    "\n",
    "**Top Table - model fit info.**\n",
    "\n",
    "  * **R-squared/Adj. R-squared** - The proportion of the variance in the response variable ('petal_width') explained by the model. The Adj. R-squared takes into account the number of variables in the model.\n",
    "  * **No. of Observations** (i.e. measurements of 'petal_width') and  **Df** degrees of freedom (No. of Observations - (1 + No. of variables in the model)).\n",
    "  * **General info** - date and time that model was run, type of model etc.\n",
    "  * **Model Fit info** - inc. **F-statistic**, **AIC** and **BIC**, **Log-Likelihood**. They are not meaningful on their own, but allow you to compare different models to assess the best one. \n",
    "    \n",
    "**Middle Table - an important table!**\n",
    "\n",
    "  * **coef** = coefficient estimates for the intercept and explanatory variables.\n",
    "  * **std err** = standard errors (i.e. estimate of the uncertainty) of the coefficient estimates.\n",
    "  * **t** = t-statistic for the t-test comparing whether the coefficient is different to 0.\n",
    "  * **P>|t|** = p-value for the t statistics, giving significance of coefficient.\n",
    "  * **[0.025 0.975]** = 95% confidence interval around the coefficient estimate.\n",
    "    \n",
    "**Bottom table - Diagnostics**\n",
    "\n",
    "  * **Jarque-Bera**, **Omnibus**: test normality of residuals.\n",
    "  * **Cond, No.**: Condition Number, test for multicollinearity.\n",
    "  * **Durbin-Watson**: test for autocorrelation.\n",
    "\n",
    "\n",
    "As you can see, there is a lot of information in the summary. Let's focus on a few relevant values from the model to focus on.\n",
    "\n",
    "\n",
    "<img src=\"../../images/linear_model_petal_width_vs_length_annotated.png\"  width=\"800\" height=\"800\" alt=\"Results of the model fit with Adjusted R-squared and coefficients and standard error highlighted.\">\n",
    "\n",
    "We can also get these specific parameters directly from the `model` object.\n",
    "\n",
    "Such as the `Intercept`, `Slope`, `R-squared`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the intercept\n",
    "\n",
    "print(\"Intercept = \",results_mod1.params['Intercept'])\n",
    "\n",
    "\n",
    "\n",
    "## Extracting the slope\n",
    "\n",
    "print(\"(Petal length) coef. = \", results_mod1.params['petal_length'])\n",
    "\n",
    "\n",
    "## Extracting the R-squared\n",
    "\n",
    "print(\"R^2 = \", results_mod1.rsquared_adj)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the line of best fit\n",
    "\n",
    "The code above is a useful way to pull out information to further analyse or include in reports. We can pull out these coefficients to plot our line of best fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot of line of best fit compared to two different slope and intercepts to describe the relationship between petal width and petal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scatter = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(7)\n",
    "a = 0.37\n",
    "a1 = 0.35\n",
    "\n",
    "b = -0.2\n",
    "b1 = -0.3\n",
    "\n",
    "y = a*x + b\n",
    "y1 = a1*x + b1\n",
    "y2 = results_mod1.params['petal_length']*x + results_mod1.params['Intercept']\n",
    "\n",
    "iris_scatter = sns.regplot(x = x, y = y, marker=\"+\")\n",
    "iris_scatter = sns.regplot(x = x, y = y1, marker=\"+\", line_kws = {\"color\": \"red\"})\n",
    "iris_scatter = sns.regplot(x = x, y = y2, marker = \"+\", line_kws = {\"color\": \"blue\"})\n",
    "iris_scatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this plot by hand (as above) or directly from our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatterplot and line of best fit\n",
    "\n",
    "iris_best_fit = sns.regplot(x = 'petal_length', y = 'petal_width', ci = 95, data = df_iris)\n",
    "iris_best_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residuals**\n",
    "\n",
    "We can get the residuals using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize = (8,5))\n",
    "\n",
    "x = df_iris.petal_length\n",
    "y = df_iris.petal_width\n",
    "\n",
    "xfit = np.arange(8)\n",
    "yfit = results_mod1.params['petal_length']*xfit + results_mod1.params['Intercept']\n",
    "\n",
    "slope = results_mod1.params['petal_length']\n",
    "intercept = results_mod1.params['Intercept']\n",
    "\n",
    "# Plot\n",
    "ax2.scatter(x,y, marker = 'x', color = 'k')\n",
    "ax2.plot(xfit, yfit, color = 'r')\n",
    "\n",
    "# plot residuals\n",
    "def residual_line(x, y, slope, intercept):\n",
    "    xs = [x, x]\n",
    "    ys = [y, (intercept + slope * x)]\n",
    "    return xs, ys\n",
    "errs = [ax2.plot(*residual_line(x, y, slope, intercept), color = '0.5')]\n",
    "ax2.set_xlabel(\"$X $\", fontsize = 12)\n",
    "ax2.set_ylabel(\"$Y $\", fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the residuals to look at the actual vs predicted values and plot these on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = df_iris.petal_width\n",
    "predicted = results_mod1.params['petal_length']*df_iris.petal_length + results_mod1.params['Intercept']\n",
    "difference = actual-predicted\n",
    "\n",
    "x = df_iris.petal_length\n",
    "\n",
    "fig, resid_plot = plt.subplots(figsize = (8,5))\n",
    "\n",
    "resid_plot.scatter(x, difference, marker = 'o', color = 'k')\n",
    "resid_plot.set_xlabel(\"Petal Length\", fontsize = 12)\n",
    "resid_plot.set_ylabel(\"Residuals\", fontsize = 12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the sum of squared residuals by taking the difference squared and then the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the sum of squared residuals we need to take the difference squared and then the square root.\n",
    "\n",
    "difference_squared = difference**2\n",
    "residuals = difference_squared.apply(math.sqrt)\n",
    "\n",
    "\n",
    "print(residuals.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residuals**\n",
    "\n",
    "We can then inspect the residuals in the model. `Residuals` represent the left over variation in the response variable not explained by the model. A pattern in the residuals may indicate that we are missing a variable or that our assumption of normality is  incorrect. When we are looking at the residuals, we want them to form an 'amorphous cloud', i.e. a cloud shape with no patterns. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><font size=\"4\"> Residual plots and assumptions </font> </b> \n",
    "<p> \n",
    "    \n",
    "* **Residuals vs Fitted:** is used to check the assumptions of linearity. If the residuals are spread equally around a horizontal line without distinct patterns (red line is approximately horizontal at zero), that is a good indication of having a linear relationship.\n",
    "\n",
    "* **Normal Q-Q:** is used to check the normality of residuals assumption. If the majority of the residuals follow the straight dashed line, then the assumption is fulfilled.\n",
    "\n",
    "* **Scale-Location:** is used to check the homoscedasticity of residuals (equal variance of residuals). If the residuals are spread randomly and the see a horizontal line with equally (randomly) spread points, then the assumption is fulfilled. \n",
    "\n",
    "* **Residuals vs Leverage:** is used to identify any influential value in our dataset. Influential values are extreme values that might influence the regression results when included or excluded from the analysis. Look for cases outside of a dashed line. \n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "We will be focusing today on residuals vs. fitted and the Normal Q-Q plot. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris_resid = sns.residplot(y = 'petal_width', x = 'petal_length', data = df_iris)\n",
    "df_iris_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there might be some patterns left in the data that are unexplained. We can see that as `petal_length` increases the variability and range of residual values also increase.\n",
    "\n",
    "**Checking for normality of the residuals**\n",
    "\n",
    "One of the assumptions of a linear model is that the residuals are normally distributed. Note that this does not mean that the response variable needs to come from a normal distribution, just that the residuals are normally distributed. Normal distributions are often referred to as bell curves because of their shape. Let's take a look at a normal distribution with mean 0 and variance 1. \n",
    "\n",
    "**Normal** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspecting the normal distribution\n",
    "\n",
    "mu = 0\n",
    "variance = 1\n",
    "sigma = math.sqrt(variance)\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you'll notice in the plot above is that it is symmetrical with most values falling close to 0. \n",
    "\n",
    "\n",
    "A common plot used to inspect model residuals is a qqplot. The qqplot compares the residuals to a theoretical normal distribution. If the residuals come from a normal distribution we would expect the blue dots to line up with the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = results_mod1.resid\n",
    "\n",
    "# Use statsmodels qqplot to graph residuals\n",
    "# make a figure and an axis\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "# call the qqplot graph from statsmodels 'graphics' module.\n",
    "# fits against the normal distribution as standard.\n",
    "sm.graphics.qqplot(resid, line='45', fit=True, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot doesn't look too bad. The residuals mostly match the red line, but we can see that the tails of the qqplot are a little skewed, particularly to the right. This may mean that there is still some structure in the variation in `petal_width` that is not accounted for by `petal_length`.  We can see whether including species in the model helps explain some of the remaining variation in the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Continuous and Categorical Variables\n",
    "\n",
    "Now we are constructing our model to explain the variation in `petal_width` using the variables for `petal_length` and `species`. In this case, because species is a categorical variable we can specify it using `C(species)`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = smf.ols(formula = 'petal_width ~ petal_length + C(species)', data = df_iris)\n",
    "\n",
    "results_mod2 = model2.fit()\n",
    "\n",
    "print(results_mod2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few key things to pick out from the table above. First, we have an increase in the adjusted R^2, which is now 0.944, meaning we've explained 94.4 \\% of the variation in petal_length. We also have several variables now:\n",
    "\n",
    " * `Intercept`\n",
    " * `C(species)[T.versicolor]`\n",
    " * `C(species)[T.virginica]`\n",
    " * `petal_length`\n",
    " \n",
    " \n",
    "But remember that in our `df_iris` dataset there are three species of iris: \n",
    "\n",
    "* setosa\n",
    "\n",
    "* versicolor\n",
    "\n",
    "* virginica\n",
    "\n",
    "Categorical variables always contribute to the intercept in a linear model. When fitting the model, the model function uses the first level of the categorical variable, in this case `setosa`, as the baseline `Intercept`. The coefficients estimated for `C(species)[T.versicolor]` and `C(species)[T.virginica]` are estimated in relation to that. \n",
    "\n",
    "Let's see how our fit looks when it is plotted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scatter_species = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(7)\n",
    "a = results_mod2.params['petal_length']\n",
    "\n",
    "b_setosa = results_mod2.params['Intercept']\n",
    "b_virginica = results_mod2.params['C(species)[T.virginica]'] + results_mod2.params['Intercept']\n",
    "b_versicolor = results_mod2.params['C(species)[T.versicolor]']  + results_mod2.params['Intercept']\n",
    "\n",
    "\n",
    "y_setosa = a*x + b_setosa\n",
    "y_virginica = a*x + b_virginica\n",
    "y_versicolor = a*x + b_versicolor\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_setosa, marker=\"+\", line_kws = {\"color\": \"blue\"})\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_virginica, marker = \"+\", line_kws = {\"color\": \"green\"})\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_versicolor, marker = \"+\", line_kws = {\"color\": \"orange\"})\n",
    "\n",
    "iris_scatter_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the plot above, all of the lines have the same slope so that they are parallel to one another. The only thing that changes is the intercept which moves the fitted line up or down.\n",
    "\n",
    "Let's see what the residuals look like for our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Residuals for Model 2\n",
    "\n",
    "resid2 = results_mod2.resid\n",
    "fitted2 = results_mod2.fittedvalues\n",
    "\n",
    "resid2_plot = sns.scatterplot(x = fitted2, y = resid2)\n",
    "resid2_plot.set(xlabel='Fitted', ylabel='Residuals')\n",
    "resid2_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use statsmodels qqplot to graph errors\n",
    "# make a figure and an axis\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "# call the qqplot graph from statsmodels 'graphics' module.\n",
    "# fits against the normal distribution as standard.\n",
    "\n",
    "sm.graphics.qqplot(resid2, line='45', fit=True, ax=ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our residuals are slightly skewed to the left. Is there something more we might be missing from the model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Interactions\n",
    "\n",
    "So far we've allowed the intercept in our model to vary by species. Let's try letting our slope change also with species. By allowing our slope to vary by species we are exploring the hypothesis that **how** `petal_width` **changes** with `petal_length` varies by species. \n",
    "\n",
    "To do this in the model, we need to use an interaction term. Interactions are included using the multiplication symbol $*$ between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifying Model 3 and the resulting model fit\n",
    "\n",
    "model3 = smf.ols(formula = 'petal_width ~ petal_length*C(species)', data = df_iris)\n",
    "\n",
    "results_mod3 = model3.fit()\n",
    "\n",
    "print(results_mod3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the results, we can see that the slope for `petal_length` also uses setosa (the species name that is missing) as a baseline.\n",
    "\n",
    "\n",
    "We can plot the model fit using our new coefficients. This time, both the slope and intercept will vary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris_scatter_species = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(7)\n",
    "\n",
    "##Slope\n",
    "a_setosa = results_mod3.params['petal_length']\n",
    "\n",
    "a_virginica = results_mod3.params['petal_length:C(species)[T.virginica]'] + results_mod3.params['petal_length']\n",
    "\n",
    "a_versicolor = results_mod3.params['petal_length:C(species)[T.versicolor]'] + results_mod3.params['petal_length']\n",
    "\n",
    "## Intercept\n",
    "b_setosa = results_mod3.params['Intercept']\n",
    "\n",
    "b_virginica = results_mod3.params['C(species)[T.virginica]'] + results_mod3.params['Intercept']\n",
    "\n",
    "b_versicolor = results_mod3.params['C(species)[T.versicolor]'] + results_mod3.params['Intercept']\n",
    "\n",
    "##Predicted Petal Width\n",
    "y_setosa = a_setosa*x + b_setosa\n",
    "\n",
    "y_virginica = a_virginica*x + b_virginica\n",
    "\n",
    "y_versicolor = a_versicolor*x + b_versicolor\n",
    "\n",
    "## Line of best fit\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_setosa, marker= \"+\", line_kws = {\"color\": \"blue\"})\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_virginica, marker = \"+\", line_kws = {\"color\": \"green\"})\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_versicolor, marker = \"+\", line_kws = {\"color\": \"orange\"})\n",
    "\n",
    "iris_scatter_species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Extrapolation**\n",
    "\n",
    "The plot above shows an important mistake that we want to avoid when plotting and using our line of best fit to make predictions.\n",
    "\n",
    "\n",
    "You'll notice from the plot above that the setosa iris petal length only ranges from 1-2 cm. This is very different from the virginica iris where the petal length ranges from 4-7. \n",
    "\n",
    "Why is this important? When we plot the line making predictions for the petal width, it's not correct to extrapolate beyond areas that we have observed, because at least in this data set, we've never seen a setosa iris with petal length 6. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><font size=\"4\">Exercise:</font></b> \n",
    "\n",
    "<p> \n",
    "\n",
    "1. Update the plot below so that the x-values, petal length, vary according to the species. For example, I've updated the x in this case to only show values for the petal length observed for the setosa species. Add an x1 and x2 for virginica and versicolor with the appropriate range of petal length values for each species.\n",
    "We also need to add `truncate = True` to the regplot function so that it does not make the line for the full x-axis.\n",
    "\n",
    "\n",
    "</p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris_scatter_species = sns.scatterplot(data = df_iris, x = 'petal_length', y = 'petal_width', hue = 'species')\n",
    "\n",
    "x = np.arange(0.8, 2.3, 0.2) # setosa\n",
    "# virginica\n",
    "# versicolor\n",
    "\n",
    "##Slope\n",
    "a_setosa = results_mod3.params['petal_length']\n",
    "\n",
    "a_virginica = results_mod3.params['petal_length:C(species)[T.virginica]'] + results_mod3.params['petal_length']\n",
    "\n",
    "a_versicolor = results_mod3.params['petal_length:C(species)[T.versicolor]'] + results_mod3.params['petal_length']\n",
    "\n",
    "## Intercept\n",
    "b_setosa = results_mod3.params['Intercept']\n",
    "\n",
    "b_virginica = results_mod3.params['C(species)[T.virginica]'] + results_mod3.params['Intercept']\n",
    "\n",
    "b_versicolor = results_mod3.params['C(species)[T.versicolor]'] + results_mod3.params['Intercept']\n",
    "\n",
    "##Predicted Petal Width\n",
    "y_setosa = a_setosa*x + b_setosa\n",
    "\n",
    "y_virginica = a_virginica*x + b_virginica\n",
    "\n",
    "y_versicolor = a_versicolor*x + b_versicolor\n",
    "\n",
    "## Line of best fit\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_setosa, marker= \"+\", line_kws = {\"color\": \"blue\"}, truncate = True)\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_virginica, marker = \"+\", line_kws = {\"color\": \"green\"})\n",
    "\n",
    "iris_scatter_species = sns.regplot(x = x, y = y_versicolor, marker = \"+\", line_kws = {\"color\": \"orange\"})\n",
    "\n",
    "iris_scatter_species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residuals Model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid3 = results_mod3.resid\n",
    "fitted3 = results_mod3.fittedvalues\n",
    "\n",
    "resid3_plot = sns.scatterplot(x = fitted3, y = resid3)\n",
    "resid3_plot.set(xlabel='Fitted', ylabel='Residuals')\n",
    "resid3_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The qqplot for Model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use statsmodels qqplot to graph errors\n",
    "# make a figure and an axis\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "# call the qqplot graph from statsmodels 'graphics' module.\n",
    "# fits against the normal distribution as standard.\n",
    "\n",
    "sm.graphics.qqplot(resid3, line='45', fit=True, ax=ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Comparison\n",
    "\n",
    "So how can we decide which model is better? There are a few metrics we can compare between the model that can be found in the top table. The three main ones we will discuss in this course are the `Adjusted R^2`, `AIC`, and `BIC`. Before getting to these concepts, let's discuss the concept of `parsimony` and `Occam's Razor`.\n",
    "\n",
    "**Occam's Razor: law of parsimony**\n",
    "\n",
    "`Parsimony` (aka `Occam's razor`) is a general argument for choosing simpler models even though we know the world is complex. Occam's razor says that when presented with competing hypotheses that make the same predictions, we should select the solution with the fewest assumptions. This is to say that all other things being equal, we should prefer a simpler model to a more complex one, especially when the data don't tell a clear story. \n",
    "\n",
    "Model selection approaches often go beyond parsimony to say that a more complex model must not be just better than, but a specified amount better than, a simpler model.\n",
    "\n",
    "**Practical Considerations**\n",
    "\n",
    "There is also a practical element to parsimony; simple theories are easier to test than complex ones. Similarly, simple models often do a better job at predicting. Because a simpler model requires fewer parameters it is also less expensive in terms of time or money to collect the data for it. \n",
    "\n",
    "**We need to draw the line somewhere**\n",
    "\n",
    "\"With four parameters I can fit an elephant, and with five I can make him wiggle his trunk\" ~ John Von Neumann\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Piotr A. Zolnierczuk (zolnierczukp at ornl dot gov)\n",
    "\n",
    "#Based on a paper by:\n",
    "#Drawing an elephant with four complex parameters\n",
    "#Jurgen Mayer, Khaled Khairy, and Jonathon Howard,\n",
    "#Am. J. Phys. 78, 648 (2010), DOI:10.1119/1.3254017\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "# elephant parameters\n",
    "p1, p2, p3, p4 = (50 - 30j, 18 +  8j, 12 - 10j, -14 - 60j )\n",
    "p5 = 40 + 20j # eyepiece\n",
    "\n",
    "def fourier(t, C):\n",
    "    f = np.zeros(t.shape)\n",
    "    A, B = C.real, C.imag\n",
    "    for k in range(len(C)):\n",
    "        f = f + A[k]*np.cos(k*t) + B[k]*np.sin(k*t)\n",
    "    return f\n",
    "\n",
    "def elephant(t, p1, p2, p3, p4, p5):\n",
    "    npar = 6\n",
    "    Cx = np.zeros((npar,), dtype='complex')\n",
    "    Cy = np.zeros((npar,), dtype='complex')\n",
    "\n",
    "    Cx[1] = p1.real*1j\n",
    "    Cx[2] = p2.real*1j\n",
    "    Cx[3] = p3.real\n",
    "    Cx[5] = p4.real\n",
    "\n",
    "    Cy[1] = p4.imag + p1.imag*1j\n",
    "    Cy[2] = p2.imag*1j\n",
    "    Cy[3] = p3.imag*1j\n",
    "\n",
    "    x = np.append(fourier(t,Cx), [-p5.imag])\n",
    "    y = np.append(fourier(t,Cy), [p5.imag])\n",
    "\n",
    "    return x,y\n",
    "\n",
    "x, y = elephant(np.linspace(0,2*np.pi,1000), p1, p2, p3, p4, p5)\n",
    "pylab.plot(y,-x,'.')\n",
    "pylab.xlabel('x')\n",
    "pylab.ylabel('y')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we add more parameters to a model, we necessarily get an increasingly accurate fit to the particular data we have observed (the bias of our predictions decreases), but our precision for predicting future observations decreases as well (the varaince of our predictions increases). \n",
    "\n",
    "One way to think about it is that data contain a fixed amount of information; as we estimate more and more parameters we spread the data thinner and thinner. Eventually the gain in accuracy from having more details in the model is outweighed by the loss in precision from estimating the effect of each of those details more poorly.\n",
    "\n",
    "**Adjusted R^2**\n",
    "\n",
    "R-squared is a goodness-of-fit measure for linear regression models. It indicates the percentage of the variance in the response variable explained by the explanatory variables. It is calculated by:\n",
    "\n",
    "\n",
    "$\\frac{\\text{Variance explained by the model}}{ \\text{Total variance}}$. \n",
    "\n",
    "**Likelihood**\n",
    "\n",
    "The `likelihood` is the probability of the observed outcome (i.e. the data) given a particular choice of parameters. For a particular statistical model, maximum likelihood finds the set of parameters *that makes the observed data most likely to have occurred*. That is, we find the set of parameters that makes the likelihood as large as possible.\n",
    "\n",
    "<img src=\"../../images/likelihood_example.png\"  width=\"800\" height=\"800\" alt=\"Maximum likelihood example.\">\n",
    "Image Credit: Ashan Priyadarshan. [Maximum likelihood](https://medium.com/quick-code/maximum-likelihood-estimation-for-regression-65f9c99f815d)\n",
    "\n",
    "The diagram above shows what is happening when you are calculating the maximum likelihood. Here, we have a line of best fit, with the estimated values of the response variable $\\hat y_{1...n}$ (red dots). The actual values of the response variable (our data), are reperesented by the black dots. The residuals are indicated by the $\\epsilon$. These residual is the distance between the actual value of the response variable and the estimated value of the response variable. \n",
    "\n",
    "When we are calculating the maximum likelihood, we are looking for the parameters that maximise the likelihood of the data. The horizontal arrows trace up to the normal distribution which represents the fit. The closer to the peak of the distribution the data falls the \"more likely\" the data is given the parameters. \n",
    "\n",
    "For mathematical convience, we often work with the logarithm of the likelihood (the *log-likelihood*) instead of the likelihood. However, the parameters that give the maximum log-likelihood also give the maximum likelihood. \n",
    "\n",
    "**Information criteria**\n",
    "\n",
    "**Information criteria** are based on the expected distance between a particular model and the \"true\" model. All information-theoretic methods reduce to finding the model that minimizes some criterion that is the sum of a term based on the likelihood (usually twice the negative log-likelihood) and a *penalty term* which is different for different information criteria. \n",
    "\n",
    "Selecting models based on information criteria allows for the comparison of all candidate models at once, provided they are fit to the same data. If there are missing values in certain variables and not others, the model will exclude these data when fitting by default, so you need to be careful that you are not comparing models which have been fit to different datasets. \n",
    "\n",
    "\n",
    " * **AIC**\n",
    "The `Akaike Information Criterion`, or AIC, is the most widespread information criterion, and is defined as\n",
    "\n",
    "$\\text{AIC} = -2L + 2k$\n",
    "\n",
    "where $L$ is the log-likelihood and $k$ is the number of parameters in the model. As with all information criteria, small values represent better overall fits; adding a parameter with a negligible improvement in fit penalizes the AIC by 2 log-likelihood units.\n",
    "\n",
    "\n",
    "**Some rough guidance for AIC**\n",
    "\n",
    "1. Lower values of AIC indicated a better fit to the data regardless of whether they are positive or negative.\n",
    "    * If you have two models with AIC: -213.09, and -289.12. The model with AIC -289.12 is better.\n",
    "2. AIC comparisons are only valid for models that are fit to the same response data (i.e. same y)\n",
    "\n",
    "For AIC, the rule of thumb people generally follow is that improvements of greater than 2 mean we can select the more complicated model.\n",
    "\n",
    "* **BIC**\n",
    "The second most common information criterion, the *Bayesian* information criterion (BIC), uses a penalty term of $(log n)k$. The BIC is more conservative than the AIC, insisting on a greater improvement in fit before it will accept a more complex model. \n",
    "\n",
    "**Model Selection when there are several possibilities**\n",
    "\n",
    "Models with multiple parameters and possible interactions between variable lead to a large number of models to try. Two simple approaches to model selection include:\n",
    "\n",
    "* **forward selection** (add parameters one at a time to the simplest model)\n",
    "* **backward selection** (subtract parameters from the most complex model). \n",
    "\n",
    "With too large a set of possibilities this can mean that you may arrive at a different best model depending on which approach you take. There are some algorithms to do a combination or forward and backward selection. However, you want to be careful that this kind of model selection does not devolve into data-dredging. \n",
    "\n",
    "You should:\n",
    "\n",
    "1. Use common sense and domain knowledge to isolate the most important comparisons\n",
    "2. Raw plots of the best candidate fits to try to understand why different models fit the data approximately equally well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><font size=\"4\"> Exercises: /font> </b> \n",
    "<p> \n",
    "\n",
    "1. Let's compare the models we ran using Adjusted R^2 and AIC. Using the notes above, discuss in groups which model you think is best and why?\n",
    "\n",
    "2. Take a look at the main parameters of Model 2 and Model 3 from the model summary tables. Do they seem to vary much between the models?\n",
    "\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "**Adjusted R^2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Comparison: Comparing Adjusted R^2\n",
    "## \\n will put the results on the next line!\n",
    "\n",
    "print(\"Adjusted R^2 Model 1 = \", results_mod1.rsquared_adj, \"\\nAdjusted R^2 Model 2 = \", results_mod2.rsquared_adj\n",
    ", \"\\nAdjusted R^2 Model 3 = \", results_mod3.rsquared_adj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIC Model 1 = \", results_mod1.aic, \"\\nAIC Model 2 = \", results_mod2.aic, \"\\nAIC Model 3 = \", results_mod3.aic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><font size=\"4\"> Case Study: Department Salaries /font> </b> \n",
    "<p> \n",
    "\n",
    "Open up the notebook to explore the department salaries.\n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
